"""Workflow orchestration tools for doc-manager."""

import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any

from ..constants import DocumentationPlatform
from ..indexing.link_rewriter import (
    extract_frontmatter,
    generate_toc,
    preserve_frontmatter,
    update_or_insert_toc,
)
from ..models import BootstrapInput, MigrateInput, SyncInput
from ..utils import detect_project_language, enforce_response_limit, handle_error
from .config import initialize_config
from .detect_changes import docmgr_detect_changes
from .memory import initialize_memory
from .platform import detect_platform
from .quality import assess_quality
from .validation import validate_docs


async def bootstrap(params: BootstrapInput) -> str | dict[str, Any]:
    """Bootstrap fresh documentation for a project.

    Orchestrates multiple tools to set up documentation from scratch:
    1. Detects/recommends documentation platform
    2. Creates configuration file
    3. Creates documentation directory structure
    4. Generates initial documentation files
    5. Initializes memory system
    6. Runs initial quality assessment

    Args:
        params (BootstrapInput): Validated input parameters containing:
            - project_path (str): Absolute path to project root
            - platform (Optional[DocumentationPlatform]): Platform to use (auto-detected if not specified)
            - docs_path (str): Where to create docs (default: "docs")

    Returns:
        str: Bootstrap report with created files and next steps

    Examples:
        - Use when: Starting documentation for a new project
        - Use when: Setting up docs for existing project without documentation

    Error Handling:
        - Returns error if project_path doesn't exist
        - Returns error if docs_path already exists (won't overwrite)
    """
    try:
        project_path = Path(params.project_path).resolve()

        if not project_path.exists():
            return enforce_response_limit(f"Error: Project path does not exist: {project_path}")

        # Check if docs already exist
        docs_path = project_path / params.docs_path
        if docs_path.exists():
            return enforce_response_limit(f"Error: Documentation directory already exists at {docs_path}. Use migrate workflow to restructure existing docs.")

        lines = ["# Documentation Bootstrap Report", ""]
        lines.append(f"**Project:** {project_path.name}")
        lines.append(f"**Started:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")

        # Step 1: Detect platform
        lines.append("## Step 1: Platform Detection")
        lines.append("")

        from ..models import DetectPlatformInput
        platform_result = await detect_platform(DetectPlatformInput(
            project_path=str(project_path)
        ))

        platform_data = platform_result if isinstance(platform_result, dict) else json.loads(platform_result)
        recommended_platform = params.platform or DocumentationPlatform(platform_data["recommendation"])

        lines.append(f"Platform selected: **{recommended_platform.value}**")
        if not params.platform:
            lines.append(f"  (Auto-detected based on: {platform_data['project_language']})")
        lines.append("")

        # Step 2: Create configuration
        lines.append("## Step 2: Configuration")
        lines.append("")

        from ..models import InitializeConfigInput
        config_result = await initialize_config(InitializeConfigInput(
            project_path=str(project_path),
            platform=recommended_platform,
            exclude_patterns=None  # Let default_factory handle it, tools will merge with DEFAULT_EXCLUDE_PATTERNS
        ))

        if "Error" in config_result:
            return enforce_response_limit(f"Error: Bootstrap failed at configuration step:\n{config_result}")

        lines.append("Created `.doc-manager.yml` configuration")
        lines.append("")

        # Step 3: Create documentation structure
        lines.append("## Step 3: Documentation Structure")
        lines.append("")

        docs_path.mkdir(parents=True, exist_ok=True)

        # Create platform-specific documentation structure
        structure: dict[str, str] = {}
        if recommended_platform == DocumentationPlatform.MKDOCS:
            structure = {
                "README.md": _create_readme_template(project_path),
                "index.md": _create_index_template(project_path),  # MkDocs uses index.md
                "getting-started/installation.md": _create_installation_template(project_path),
                "getting-started/quick-start.md": _create_quickstart_template(project_path),
                "guides/basic-usage.md": _create_usage_template(project_path),
                "reference/configuration.md": _create_config_reference_template(project_path),
            }
        elif recommended_platform == DocumentationPlatform.HUGO:
            structure = {
                "README.md": _create_readme_template(project_path),
                "content/_index.md": _create_index_template(project_path),  # Hugo uses content/_index.md
                "content/getting-started/installation.md": _create_installation_template(project_path),
                "content/getting-started/quick-start.md": _create_quickstart_template(project_path),
                "content/guides/basic-usage.md": _create_usage_template(project_path),
                "content/reference/configuration.md": _create_config_reference_template(project_path),
            }
        elif recommended_platform == DocumentationPlatform.DOCUSAURUS:
            structure = {
                "README.md": _create_readme_template(project_path),
                "intro.md": _create_index_template(project_path),  # Docusaurus uses intro.md
                "getting-started/installation.md": _create_installation_template(project_path),
                "getting-started/quick-start.md": _create_quickstart_template(project_path),
                "guides/basic-usage.md": _create_usage_template(project_path),
                "reference/configuration.md": _create_config_reference_template(project_path),
            }
        created_files = []
        for relative_path, content in structure.items():
            file_path = docs_path / relative_path
            file_path.parent.mkdir(parents=True, exist_ok=True)

            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)

            created_files.append(str(file_path.relative_to(project_path)))

        lines.append(f"Created {len(created_files)} documentation files:")
        for file in created_files:
            lines.append(f"  - {file}")
        lines.append("")

        # Step 4: Initialize memory system
        lines.append("## Step 4: Memory System")
        lines.append("")

        from ..models import InitializeMemoryInput
        memory_result = await initialize_memory(InitializeMemoryInput(
            project_path=str(project_path)
        ))

        if "Error" in memory_result:
            return enforce_response_limit(f"Error: Bootstrap failed at memory initialization:\n{memory_result}")

        lines.append("Initialized memory system with baseline checksums")
        lines.append("")

        # Step 5: Initial quality assessment
        lines.append("## Step 5: Initial Quality Assessment")
        lines.append("")

        from ..models import AssessQualityInput
        quality_result = await assess_quality(AssessQualityInput(
            project_path=str(project_path),
            docs_path=params.docs_path
        ))

        quality_data = quality_result if isinstance(quality_result, dict) else json.loads(quality_result)
        overall_score = quality_data.get("overall_score", "unknown")

        lines.append(f"Initial quality score: **{overall_score}**")
        lines.append("  (This will improve as you fill in the template content)")
        lines.append("")

        # Summary and next steps
        lines.append("## Summary")
        lines.append("")
        lines.append("Documentation bootstrapped successfully!")
        lines.append("")
        lines.append("**What was created:**")
        lines.append("- Configuration: `.doc-manager.yml`")
        lines.append(f"- Documentation: `{params.docs_path}/` with {len(created_files)} files")
        lines.append("- Memory system: `.doc-manager/memory/`")
        lines.append("")

        lines.append("## Next Steps")
        lines.append("")
        lines.append("1. **Customize templates**: Fill in project-specific content in the created files")
        lines.append("2. **Add examples**: Include code examples and screenshots")
        lines.append("3. **Configure platform**: Set up your chosen documentation platform")
        lines.append("4. **Run validation**: Use `docmgr_validate_docs` to check for issues")
        lines.append("5. **Assess quality**: Use `docmgr_assess_quality` to measure improvements")
        lines.append("")

        lines.append("**Platform-Specific Setup:**")
        if recommended_platform == DocumentationPlatform.HUGO:
            lines.append("- Install Hugo: `brew install hugo` or download from hugo.io")
            lines.append("- Initialize site: `hugo new site . --force`")
            lines.append("- Add theme: `git submodule add <theme-url> themes/<theme-name>`")
        elif recommended_platform == DocumentationPlatform.MKDOCS:
            lines.append("- Install MkDocs: `pip install mkdocs`")
            lines.append("- Create config: `mkdocs new .`")
            lines.append("- Choose theme in `mkdocs.yml`")
        elif recommended_platform == DocumentationPlatform.DOCUSAURUS:
            lines.append("- Install Node.js/npm if not present")
            lines.append("- Initialize: `npx create-docusaurus@latest . classic`")
            lines.append("- Move generated docs to match structure")

        return {
            "status": "success",
            "message": "Documentation bootstrapped successfully",
            "report": "\n".join(lines),
            "project": project_path.name,
            "platform": recommended_platform.value,
            "docs_path": params.docs_path,
            "files_created": len(created_files),
            "steps": {
                "platform_detection": "completed",
                "configuration": "completed",
                "structure_creation": "completed",
                "memory_initialization": "completed",
                "quality_assessment": "completed"
            },
            "created_files": created_files,
            "quality_score": overall_score
        }
    except Exception as e:
        return enforce_response_limit(handle_error(e, "bootstrap"))


def _create_readme_template(project_path: Path) -> str:
    """Create README.md template."""
    project_name = project_path.name
    return f"""# {project_name} Documentation

Welcome to the {project_name} documentation!

## Quick Links

- [Installation](getting-started/installation.md)
- [Quick Start](getting-started/quick-start.md)
- [Guides](guides/basic-usage.md)
- [Configuration Reference](reference/configuration.md)

## About

[Add a brief description of your project here]

## Getting Help

[Add information about how users can get help - links to issue tracker, community channels, etc.]

## Contributing

[Add link to contributing guide if applicable]
"""


def _create_index_template(project_path: Path) -> str:
    """Create index page template."""
    project_name = project_path.name
    return f"""# {project_name}

## Overview

[Provide a comprehensive overview of your project, its purpose, and key features]

## Key Features

- Feature 1
- Feature 2
- Feature 3

## Quick Example

```
[Add a simple code example showing basic usage]
```

## Documentation Sections

### Getting Started
Learn how to install and start using {project_name}.

### Guides
Step-by-step tutorials for common tasks.

### Reference
Detailed technical reference documentation.
"""


def _create_installation_template(project_path: Path) -> str:
    """Create installation guide template."""
    language = detect_project_language(project_path)

    content = """# Installation

## Prerequisites

[List required software, versions, etc.]

## Installation Methods

### Method 1: [Primary method]

[Provide installation instructions for your primary installation method]

"""

    if language == "Python":
        content += """```bash
pip install {project_name}
```
"""
    elif language == "Go":
        content += """```bash
go install github.com/your-org/{project_name}@latest
```
"""
    elif language in ["JavaScript/TypeScript", "Node.js"]:
        content += """```bash
npm install {project_name}
# or
yarn add {project_name}
```
"""

    content += """
### Method 2: [Alternative method]

[Provide alternative installation method if applicable]

## Verification

[Explain how users can verify the installation was successful]

```bash
[command to verify installation]
```

## Troubleshooting

[Add common installation issues and solutions]
"""

    return content


def _create_quickstart_template(project_path: Path) -> str:
    """Create quick start guide template."""
    project_name = project_path.name
    return f"""# Quick Start

Get up and running with {project_name} in 5 minutes.

## Step 1: Installation

See [Installation Guide](installation.md) for detailed instructions.

## Step 2: Basic Configuration

[Provide minimal configuration needed to get started]

## Step 3: Your First [Task]

[Walk through a simple, practical example]

```bash
[commands or code]
```

## Next Steps

- [Link to more detailed guides]
- [Link to examples]
- [Link to API reference]
"""


def _create_usage_template(project_path: Path) -> str:
    """Create basic usage guide template."""
    return """# Basic Usage

## Common Tasks

### Task 1: [Common task name]

[Step-by-step instructions]

```bash
[example command or code]
```

### Task 2: [Another common task]

[Instructions]

```bash
[example]
```

## Best Practices

[Add recommended practices for using the tool/library]

## Examples

### Example 1: [Realistic scenario]

[Full example with explanation]

## See Also

- [Link to related guides]
- [Link to API reference]
"""


def _create_config_reference_template(project_path: Path) -> str:
    """Create configuration reference template."""
    return """# Configuration Reference

## Configuration File

[Describe the configuration file format, location, and structure]

## Configuration Options

### Option 1

- **Type**: [string/number/boolean/etc.]
- **Default**: [default value]
- **Required**: [yes/no]
- **Description**: [What this option does]

**Example:**
```yaml
option1: value
```

### Option 2

[Repeat for each configuration option]

## Environment Variables

[Document environment variables if applicable]

## Configuration Examples

### Example 1: [Common configuration scenario]

```yaml
[full configuration example]
```

### Example 2: [Another scenario]

```yaml
[configuration]
```
"""


async def migrate(params: MigrateInput) -> str | dict[str, Any]:
    """Migrate existing documentation to new structure.

    Orchestrates documentation restructuring:
    1. Assesses existing documentation quality
    2. Detects current and target platforms
    3. Creates new documentation structure
    4. Moves/copies files preserving git history (if requested)
    5. Updates internal links and references
    6. Generates migration report with breaking changes

    Args:
        params (MigrateInput): Validated input parameters containing:
            - project_path (str): Absolute path to project root
            - existing_docs_path (str): Current docs location (relative)
            - new_docs_path (str): New docs location (default: "docs-new")
            - target_platform (Optional[DocumentationPlatform]): Target platform
            - preserve_history (bool): Use git mv to preserve history (default: True)

    Returns:
        str: Migration report with moved files and breaking changes

    Examples:
        - Use when: Restructuring existing documentation
        - Use when: Migrating to a different documentation platform
        - Use when: Consolidating scattered documentation

    Error Handling:
        - Returns error if project_path doesn't exist
        - Returns error if existing_docs_path doesn't exist
        - Returns error if new_docs_path already exists
    """
    try:
        project_path = Path(params.project_path).resolve()

        if not project_path.exists():
            return enforce_response_limit(f"Error: Project path does not exist: {project_path}")

        # Validate existing docs path
        existing_docs = project_path / params.source_path
        if not existing_docs.exists():
            return enforce_response_limit(f"Error: Existing documentation path does not exist: {existing_docs}")

        # Validate new docs path
        new_docs = project_path / params.target_path
        if new_docs.exists():
            return enforce_response_limit(f"Error: New documentation path already exists: {new_docs}. Please choose a different path or remove the existing directory.")

        lines = ["# Documentation Migration Report", ""]
        lines.append(f"**Project:** {project_path.name}")
        lines.append(f"**Started:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")

        # Step 1: Assess existing documentation
        lines.append("## Step 1: Existing Documentation Assessment")
        lines.append("")

        from ..models import AssessQualityInput
        quality_result = await assess_quality(AssessQualityInput(
            project_path=str(project_path),
            docs_path=params.source_path
        ))

        quality_data = quality_result if isinstance(quality_result, dict) else json.loads(quality_result)
        existing_score = quality_data.get("overall_score", "unknown")

        lines.append(f"Existing documentation quality: **{existing_score}**")
        lines.append("")

        # Step 2: Detect platforms
        lines.append("## Step 2: Platform Detection")
        lines.append("")

        from ..models import DetectPlatformInput
        platform_result = await detect_platform(DetectPlatformInput(
            project_path=str(project_path)
        ))

        platform_data = platform_result if isinstance(platform_result, dict) else json.loads(platform_result)
        current_platform = platform_data.get("recommendation", "unknown")
        target_platform = params.target_platform.value if params.target_platform else current_platform

        lines.append(f"Current platform: **{current_platform}**")
        lines.append(f"Target platform: **{target_platform}**")
        lines.append("")

        # Step 3: Create new structure
        step_header = "## Step 3: Creating New Structure"
        if params.dry_run:
            step_header += " (DRY RUN - Preview Only)"
        lines.append(step_header)
        lines.append("")

        moved_files = []
        link_updates_needed = []
        broken_links = []
        links_rewritten = 0
        tocs_generated = 0

        # Process files one by one for link rewriting and TOC generation
        try:
            # Create target directory if not dry run
            if not params.dry_run:
                new_docs.mkdir(parents=True, exist_ok=False)

            # Process all files from existing docs
            for old_file in existing_docs.rglob("*"):
                if not old_file.is_file():
                    continue

                relative_path = old_file.relative_to(existing_docs)
                new_file = new_docs / relative_path

                # Create parent directories if not dry run
                if not params.dry_run:
                    new_file.parent.mkdir(parents=True, exist_ok=True)

                # Process markdown files with link rewriting/TOC
                if old_file.suffix.lower() in ['.md', '.markdown']:
                    content = old_file.read_text(encoding='utf-8')

                    # Extract frontmatter
                    frontmatter_dict, body = extract_frontmatter(content)

                    # Rewrite links if enabled
                    if params.rewrite_links:
                        from ..indexing.link_rewriter import (
                            compute_link_mappings,
                            rewrite_links_in_content,
                        )

                        link_mappings = compute_link_mappings(
                            body,
                            new_file,
                            existing_docs,
                            new_docs,
                            project_path
                        )

                        if link_mappings:
                            body = rewrite_links_in_content(body, link_mappings)
                            links_rewritten += 1

                    # Regenerate TOC if enabled
                    if params.regenerate_toc and '<!-- TOC -->' in content:
                        toc = generate_toc(body, max_depth=3)
                        body = update_or_insert_toc(body, toc)
                        tocs_generated += 1

                    # Reconstruct with frontmatter
                    if frontmatter_dict:
                        final_content = preserve_frontmatter(frontmatter_dict, body)
                    else:
                        final_content = body

                    # Write file if not dry run
                    if not params.dry_run:
                        new_file.write_text(final_content, encoding='utf-8')

                else:
                    # Non-markdown files: just copy
                    if not params.dry_run:
                        shutil.copy2(old_file, new_file)

                moved_files.append({
                    "old": str(old_file.relative_to(project_path)),
                    "new": str(new_file.relative_to(project_path)),
                    "method": "copy" if not params.dry_run else "preview"
                })

        except Exception as e:
            return enforce_response_limit(f"Error: Failed to migrate documentation: {e}")

        if params.dry_run:
            lines.append(f"Would migrate {len(moved_files)} documentation files (DRY RUN)")
        else:
            lines.append(f"Migrated {len(moved_files)} documentation files")

        if params.rewrite_links:
            lines.append(f"  - Links rewritten in {links_rewritten} markdown files")
        if params.regenerate_toc:
            lines.append(f"  - TOC regenerated in {tocs_generated} markdown files")
        lines.append("")

        # Step 4: Update internal links
        if not params.dry_run:
            lines.append("## Step 4: Link Updates")
            lines.append("")

            # Scan for broken links in new structure
            from ..models import ValidateDocsInput
            validation_result = await validate_docs(ValidateDocsInput(
                project_path=str(project_path),
                docs_path=params.target_path,
                check_links=True,
                check_assets=False,
                check_snippets=False
            ))

            validation_data = validation_result if isinstance(validation_result, dict) else json.loads(validation_result)
            broken_links = [issue for issue in validation_data.get("issues", []) if issue.get("type") == "broken_link"]

            if broken_links:
                lines.append(f"Warning:  Found {len(broken_links)} broken links that need updating")
                link_updates_needed = broken_links[:10]  # Show first 10
                for link in link_updates_needed:
                    lines.append(f"  - {link.get('file')}:{link.get('line')} - {link.get('link_url')}")
                if len(broken_links) > 10:
                    lines.append(f"  ... and {len(broken_links) - 10} more")
            else:
                lines.append("No broken links detected")
            lines.append("")

            # Step 5: Quality assessment of migrated docs
            lines.append("## Step 5: Post-Migration Quality Assessment")
            lines.append("")

            new_quality_result = await assess_quality(AssessQualityInput(
                project_path=str(project_path),
                docs_path=params.target_path
            ))

            new_quality_data = new_quality_result if isinstance(new_quality_result, dict) else json.loads(new_quality_result)
            new_score = new_quality_data.get("overall_score", "unknown")

            lines.append(f"Migrated documentation quality: **{new_score}**")

            if existing_score != new_score:
                lines.append(f"  (Changed from {existing_score})")

            lines.append("")
        else:
            lines.append("## Dry Run Complete")
            lines.append("")
            lines.append("No files were actually modified. Re-run without dry_run to apply changes.")
            lines.append("")

        # Summary
        lines.append("## Migration Summary")
        lines.append("")
        lines.append("**Migration completed successfully!**")
        lines.append("")
        lines.append("**Files Migrated:**")
        lines.append(f"- Total files: {len(moved_files)}")

        git_mv_count = len([f for f in moved_files if f["method"] == "git mv"])
        copy_count = len([f for f in moved_files if f["method"] == "copy"])

        if git_mv_count > 0:
            lines.append(f"- Git history preserved: {git_mv_count} files")
        if copy_count > 0:
            lines.append(f"- Copied: {copy_count} files")

        lines.append("")
        lines.append("**Breaking Changes:**")

        if broken_links:
            lines.append(f"- {len(broken_links)} broken links need manual updates")
        lines.append("")

        # Next steps
        lines.append("## Next Steps")
        lines.append("")
        lines.append("1. **Review migrated content**: Check that all files moved correctly")

        if broken_links:
            lines.append("2. **Update broken links**: Fix internal links to match new structure")

        lines.append("3. **Update references**: Update any external references to old doc paths")
        lines.append("4. **Test new structure**: Ensure documentation builds correctly")
        lines.append(f"5. **Remove old docs**: After verification, remove `{params.source_path}/`")
        lines.append("6. **Update configuration**: Update `.doc-manager.yml` if needed")
        lines.append("")

        lines.append("**Migration Files:**")
        lines.append(f"- Old location: `{params.source_path}/`")
        lines.append(f"- New location: `{params.target_path}/`")

        return {
            "status": "success",
            "message": "Documentation migrated successfully",
            "report": "\n".join(lines),
            "source_path": params.source_path,
            "target_path": params.target_path,
            "target_platform": params.target_platform.value if params.target_platform else target_platform,
            "files_migrated": len(moved_files),
            "broken_links": len(broken_links) if broken_links else 0,
            "steps": {
                "assessment": "completed",
                "platform_detection": "completed",
                "copy": "completed",
                "link_detection": "completed",
                "quality_check": "completed"
            },
            "migrated_files": moved_files
        }
    except Exception as e:
        return enforce_response_limit(handle_error(e, "migrate"))


async def sync(params: SyncInput) -> dict[str, Any] | str:
    """Sync documentation with code changes.

    Orchestrates documentation synchronization with two modes:
    - mode="check": Read-only analysis (detects changes, no baseline updates)
    - mode="resync": Full sync (detects changes + updates baselines atomically)

    Steps performed:
    1. Maps code changes to affected documentation
    2. Identifies documentation that needs updates
    3. Validates current documentation state
    4. Assesses documentation quality
    5. Updates baselines (only if mode="resync")
    6. Generates sync report with actionable recommendations

    Args:
        params (SyncInput): Validated input parameters containing:
            - project_path (str): Absolute path to project root
            - mode (str): "check" (read-only) or "resync" (update baselines)
            - docs_path (str): Documentation directory path
            - response_format (ResponseFormat): Output format

    Returns:
        dict: Sync report with affected docs, recommendations, and baseline status

    Examples:
        - Use when: After making code changes (mode="check" to analyze impact)
        - Use when: After updating docs (mode="resync" to update baselines)
        - Use when: Running in CI/CD to detect doc staleness (mode="check")

    Error Handling:
        - Returns error if project_path doesn't exist
        - Returns error if memory baseline not found
        - Returns info if no changes detected
    """
    try:
        project_path = Path(params.project_path).resolve()

        if not project_path.exists():
            return enforce_response_limit(f"Error: Project path does not exist: {project_path}")

        lines = ["# Documentation Sync Report", ""]
        lines.append(f"**Project:** {project_path.name}")
        lines.append(f"**Mode:** {params.mode} ({'read-only analysis' if params.mode == 'check' else 'analysis + baseline update'})")
        lines.append(f"**Started:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")

        # Step 1: Map code changes
        lines.append("## Step 1: Change Detection")
        lines.append("")

        # Check if baseline exists
        baseline_path = project_path / ".doc-manager" / "memory" / "repo-baseline.json"
        if not baseline_path.exists():
            return enforce_response_limit("Error: No baseline found. Please run docmgr_init first to establish a baseline for change detection.")

        from ..constants import ChangeDetectionMode
        from ..models import DocmgrDetectChangesInput
        changes_result = await docmgr_detect_changes(DocmgrDetectChangesInput(
            project_path=str(project_path),
            mode=ChangeDetectionMode.CHECKSUM
        ))

        changes_data = changes_result if isinstance(changes_result, dict) else json.loads(changes_result)
        changes_detected = changes_data.get("changes_detected", False)
        total_changes = changes_data.get("total_changes", 0)
        affected_docs = changes_data.get("affected_documentation", [])

        if not changes_detected:
            return {
                "status": "success",
                "message": "No changes detected",
                "changes": 0,
                "affected_docs": 0,
                "recommendations": []
            }

        lines.append(f"Warning:  Detected {total_changes} code changes")
        lines.append("")

        # Step 2: Identify affected documentation
        lines.append("## Step 2: Affected Documentation")
        lines.append("")

        if not affected_docs:
            lines.append("No documentation impacts detected")
            lines.append("  (Changes only affected tests, infrastructure, or docs themselves)")
            lines.append("")
        # Step 3: Validate current documentation
        lines.append("## Step 3: Current Documentation Status")
        lines.append("")

        from ..models import ValidateDocsInput
        from ..utils import find_docs_directory

        # Use provided docs_path or auto-detect
        if params.docs_path:
            docs_path = project_path / params.docs_path
        else:
            docs_path = find_docs_directory(project_path)

        # Initialize validation metrics
        total_issues: int | None = None

        if docs_path and docs_path.exists():
            validation_result = await validate_docs(ValidateDocsInput(
                project_path=str(project_path),
                docs_path=str(docs_path.relative_to(project_path))
            ))

            validation_data = validation_result if isinstance(validation_result, dict) else json.loads(validation_result)
            total_issues = validation_data.get("total_issues", 0)
            errors = validation_data.get("errors", 0)
            warnings = validation_data.get("warnings", 0)

            if total_issues == 0:
                lines.append("No validation issues found")
            else:
                lines.append(f"Warning:  Found {total_issues} validation issues:")
                lines.append(f"  - Errors: {errors}")
                lines.append(f"  - Warnings: {warnings}")
            lines.append("")
        # Step 4: Quality assessment
        lines.append("## Step 4: Quality Assessment")
        lines.append("")

        # Initialize quality metrics
        overall_score: str | None = None

        if docs_path:
            from ..models import AssessQualityInput
            quality_result = await assess_quality(AssessQualityInput(
                project_path=str(project_path),
                docs_path=str(docs_path.relative_to(project_path))
            ))

            quality_data = quality_result if isinstance(quality_result, dict) else json.loads(quality_result)
            overall_score = quality_data.get("overall_score", "unknown")

            lines.append(f"**Overall Quality:** {overall_score}")

            # Show specific criteria that need attention
            criteria = quality_data.get("criteria", [])
            low_scores = [c for c in criteria if c.get("score") in ["fair", "poor"]]

            if low_scores:
                lines.append("")
                lines.append("**Areas Needing Attention:**")
                for criterion in low_scores:
                    lines.append(f"- {criterion['criterion'].capitalize()}: {criterion['score']}")

            lines.append("")
        # Step 5: Update baselines (only if mode="resync")
        baseline_updated = False
        if params.mode == "resync":
            lines.append("## Step 5: Updating Baselines")
            lines.append("")

            from ..models import DocmgrUpdateBaselineInput
            from .update_baseline import docmgr_update_baseline

            baseline_result = await docmgr_update_baseline(
                DocmgrUpdateBaselineInput(
                    project_path=str(project_path),
                    docs_path=params.docs_path
                )
            )

            if baseline_result.get("status") == "success":
                updated_files = baseline_result.get("updated_files", [])
                lines.append(f"Successfully updated {len(updated_files)} baseline files:")
                for file in updated_files:
                    lines.append(f"  - {file}")
                baseline_updated = True
            else:
                lines.append(f"Warning: Baseline update failed: {baseline_result.get('message', 'Unknown error')}")

            lines.append("")

        # Step 6: Recommendations
        lines.append(f"## {'Step 6: ' if params.mode == 'resync' else 'Step 5: '}Recommendations")
        lines.append("")

        if affected_docs:
            lines.append("**Affected Documentation:**")
            lines.append("")
            for doc in affected_docs[:10]:
                lines.append(f"- {doc['file']} (Priority: {doc.get('priority', 'medium')})")

            if len(affected_docs) > 10:
                lines.append(f"  ... and {len(affected_docs) - 10} more")

            lines.append("")
            lines.append("**Recommended Actions:**")
            lines.append("1. Review and update affected documentation")
            lines.append("2. Check that examples still work")
            lines.append("3. Update screenshots if UI changed")
            lines.append("4. Verify configuration examples")
            lines.append("")

        if params.mode == "check":
            lines.append("**Next Steps:**")
            lines.append("- After updating docs, run sync with mode='resync' to update baselines")
            lines.append("- Or use docmgr_update_baseline to explicitly update baselines")
        elif params.mode == "resync" and baseline_updated:
            lines.append("**Baseline Status:**")
            lines.append("- All baselines updated successfully")
            lines.append("- Documentation is now in sync with current codebase")

        lines.append("")

        # Summary
        lines.append("## Summary")
        lines.append("")
        lines.append(f"**Code Changes:** {total_changes} files modified")
        lines.append(f"**Documentation Impact:** {len(affected_docs)} files affected")

        if docs_path:
            lines.append(f"**Validation Issues:** {total_issues if total_issues is not None else 'N/A'}")
            lines.append(f"**Quality Score:** {overall_score if overall_score is not None else 'N/A'}")

        if params.mode == "resync":
            lines.append(f"**Baselines Updated:** {'Yes' if baseline_updated else 'No'}")

        return {
            "status": "success",
            "message": f"Sync {'analysis' if params.mode == 'check' else 'and baseline update'} completed",
            "mode": params.mode,
            "report": "\n".join(lines),
            "changes": total_changes,
            "affected_docs": len(affected_docs),
            "recommendations": [doc["file"] for doc in affected_docs[:10]],
            "validation_issues": total_issues,
            "quality_score": overall_score,
            "baseline_updated": baseline_updated if params.mode == "resync" else None
        }
    except Exception as e:
        return enforce_response_limit(handle_error(e, "sync"))
